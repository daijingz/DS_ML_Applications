{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8658571",
   "metadata": {},
   "source": [
    "# Third Method Neural Network Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfb1fd",
   "metadata": {},
   "source": [
    "<p><b>Author</b>: Jingze Dai</p>\n",
    "<p><b>McMaster University</b>, Honors Computer Science (Coop) student</p>\n",
    "<p><b>Personal Email Address</b>: <a>david1147062956@gmail.com</a>, or <a>dai.jingze@icloud.com</a></p>\n",
    "<a href=\"https://github.com/daijingz\">Github Homepage</a>\n",
    "<a href=\"https://www.linkedin.com/in/jingze-dai/\">Linkedin Webpage</a>\n",
    "<a href=\"https://leetcode.com/david1147062956/\">Leetcode Webpage</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3259fc7",
   "metadata": {},
   "source": [
    "<i>The original research's third featuring method with its corresponding ANN, CNN, and LSTM implementations.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59329c21",
   "metadata": {},
   "source": [
    "<i>Your Feedback is important for Jingze's further development. If you want to give feedback and suggestions, or you want to participate in working and learning together, please email Jingze at dai.jingze@icloud.com. If you want Jingze to provide contributions to your research or opensource project or you want Jingze to help you with any programming issues, please email Jingze at david1147062956@gmail.com. Thank you for your help.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4443b46",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Section 1: Selected Features](#bullet1)\n",
    "* [Section 2: Extract and Load Datasets](#bullet2)\n",
    "* [Section 3: Classification (Binary Classification Approach (BCA))](#bullet3)\n",
    "* [Section 4: Classification (A Multi-class Classification Approach for Three Classes (MCATC))](#bullet4)\n",
    "* [Section 5: Classification (A Classic Learning Approach for Multi-class classification (C-LAMC))](#bullet5)\n",
    "* [Section 6: Improvement Works on C-LAMC Classifications](#bullet6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de4d27",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet1\"><p><b>Section 1</b>: Selected Features</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92078f20",
   "metadata": {},
   "source": [
    "There are 12 features selected: `posx`, `posy`, `spdx`, `spdy`, `spdx_n`, `spdy_n`, `aclx`, `acly`, `hedx`, `hedy`,`hedx_n`, and `hedy_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a93a4",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet2\"><p><b>Section 2</b>: Extract and Load Datasets</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244356c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\david\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28165c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72943321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11384b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ab1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\david\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from scipy) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32cdabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type      sendTime  sender  senderPseudo  messageID  class        posx  \\\n",
      "0     4  72002.302942  130137     101301377  422013806      0  266.982401   \n",
      "1     4  72003.302942  130137     101301377  422023410      0  266.827208   \n",
      "2     4  72004.302942  130137     101301377  422032081      0  266.420297   \n",
      "3     4  72005.302942  130137     101301377  422040712      0  268.912026   \n",
      "4     4  72006.302942  130137     101301377  422052949      0  268.242276   \n",
      "\n",
      "        posy  posz    posx_n  ...  aclz    aclx_n    acly_n  aclz_n      hedx  \\\n",
      "0  32.336955   0.0  3.480882  ...   0.0  0.000862  0.000862     0.0 -0.102790   \n",
      "1  34.624145   0.0  3.546261  ...   0.0  0.000107  0.001040     0.0 -0.099856   \n",
      "2  38.836461   0.0  3.544045  ...   0.0  0.000172  0.001661     0.0 -0.099856   \n",
      "3  45.414229   0.0  3.340080  ...   0.0  0.000171  0.001654     0.0 -0.100172   \n",
      "4  53.729986   0.0  3.328872  ...   0.0  0.000193  0.001852     0.0 -0.097105   \n",
      "\n",
      "       hedy  hedz     hedx_n     hedy_n  hedz_n  \n",
      "0  0.994703   0.0  20.038218  17.541001     0.0  \n",
      "1  0.995002   0.0  20.441139  14.467283     0.0  \n",
      "2  0.995002   0.0  20.850473  11.941528     0.0  \n",
      "3  0.994970   0.0  21.323229   9.633965     0.0  \n",
      "4  0.995274   0.0  21.788034   7.824555     0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "# Load the dataset\n",
    "output_file = 'mixalldata_clean.csv'\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8333a",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet3\"><p><b>Section 3</b>: Classification (Binary Classification Approach (BCA))</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c915a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1ms/step - accuracy: 0.6902 - loss: 0.6245 - val_accuracy: 0.7628 - val_loss: 0.4963\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 769us/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 760us/step - accuracy: 0.7614 - loss: 0.4966\n",
      "ANN Accuracy: 0.7618277668952942\n",
      "ANN Precision: 0.9234229960308048\n",
      "ANN Recall: 0.4504236618110434\n",
      "ANN F1-score: 0.6054992599044486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tffrom tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a7ebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5728 - val_accuracy: 0.7898 - val_loss: 0.4625\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 998us/step\n",
      "CNN Accuracy: 0.7885555009531083\n",
      "CNN Precision: 0.9614509943815215\n",
      "CNN Recall: 0.498941327563665\n",
      "CNN F1-score: 0.6569572139151896\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
    "precision = precision_score(Y_test, Y_pred_binary)\n",
    "recall = recall_score(Y_test, Y_pred_binary)\n",
    "f1 = f1_score(Y_test, Y_pred_binary)\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f84a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.5038 - val_accuracy: 0.7914 - val_loss: 0.4638\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.4651\n",
      "LSTM Accuracy: 0.7911252975463867\n",
      "LSTM Precision: 0.9606103203889181\n",
      "LSTM Recall: 0.5060184274568336\n",
      "LSTM F1-score: 0.662862397094003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy)\n",
    "print(\"LSTM Precision:\", precision)\n",
    "print(\"LSTM Recall:\", recall)\n",
    "print(\"LSTM F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0fa6f3",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet4\"><p><b>Section 4</b>: Classification (A Multi-class Classification Approach for Three Classes (MCATC))</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf270a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 3ms/step - accuracy: 0.3344 - loss: -4652460.0000 - val_accuracy: 0.3753 - val_loss: -68858608.0000\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - accuracy: 0.3735 - loss: -69851048.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 0.37397685647010803\n",
      "ANN Precision: 0.43353787181448067\n",
      "ANN Recall: 0.37397685621367155\n",
      "ANN F1-score: 0.3640409172827655\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3baf7e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7195 - loss: 0.7487 - val_accuracy: 0.7660 - val_loss: 0.6638 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7539 - loss: 0.6862 - val_accuracy: 0.7732 - val_loss: 0.6497 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1ms/step - accuracy: 0.7594 - loss: 0.6762 - val_accuracy: 0.7758 - val_loss: 0.6430 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1ms/step - accuracy: 0.7624 - loss: 0.6705 - val_accuracy: 0.7794 - val_loss: 0.6353 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m62919/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7640 - loss: 0.6674"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20032\\2454974639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# Evaluating the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    327\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m                     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m                     callbacks.on_train_batch_end(\n\u001b[0;32m    331\u001b[0m                         \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    876\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m       )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1321\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mflat_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1501\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define the function to characterize class\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# List of features\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "# Preparing data\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "Y = to_categorical(Y)  # Convert to one-hot encoding\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # Adjusted for multi-class classification\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping and learning rate reduction on plateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluating the model\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Computing metrics\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "# Printing the results\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845bcf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5ms/step - accuracy: 0.3406 - loss: -4908548.5000 - val_accuracy: 0.3646 - val_loss: -70431504.0000\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.3637462008695353\n",
      "CNN Precision: 0.42212103826182124\n",
      "CNN Recall: 0.3637462008695353\n",
      "CNN F1-score: 0.354193808658255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
    "precision = precision_score(Y_test, Y_pred_binary, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred_binary, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred_binary, average='weighted')\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30603df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 13ms/step - accuracy: 0.4560 - loss: -70.9306 - val_accuracy: 0.3963 - val_loss: -326.7960\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.3959 - loss: -327.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Accuracy: 0.3964727222919464\n",
      "LSTM Precision: 0.46413267372450967\n",
      "LSTM Recall: 0.3964727166873773\n",
      "LSTM F1-score: 0.38950174668682536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy)\n",
    "print(\"LSTM Precision:\", precision)\n",
    "print(\"LSTM Recall:\", recall)\n",
    "print(\"LSTM F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c36f191",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet5\"><p><b>Section 5</b>: Classification (A Classic Learning Approach for Multi-class classification (C-LAMC))</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccdb9194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1ms/step - accuracy: 0.0138 - loss: -116202307584.0000 - val_accuracy: 0.0137 - val_loss: -1664064421888.0000\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 753us/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 812us/step - accuracy: 0.0136 - loss: -1679659106304.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 0.013424898497760296\n",
      "ANN Precision: 0.00018022789993040557\n",
      "ANN Recall: 0.013424898507266473\n",
      "ANN F1-score: 0.0003556808209387275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8fa27",
   "metadata": {},
   "source": [
    "Here is an early-stage improved version of the ANN network above, which adds more layers. The accuracy has been increased a lot without considering the instability problem. -> That is, abnormal values of the statistics `loss` and `val_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57046476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2ms/step - accuracy: 0.0138 - loss: -3792197187379658752.0000 - val_accuracy: 0.0137 - val_loss: -109648269314380267520.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2ms/step - accuracy: 0.0137 - loss: -390503464514598469632.0000 - val_accuracy: 0.0137 - val_loss: -2584283122725455659008.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2ms/step - accuracy: 0.0137 - loss: -4888723260655223701504.0000 - val_accuracy: 0.0137 - val_loss: -17266669241049381076992.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.2669 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: nan - val_accuracy: 0.5952 - val_loss: nan\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 964us/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.5937 - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 0.594205915927887\n",
      "ANN Precision: 0.35308066968094687\n",
      "ANN Recall: 0.5942059152187454\n",
      "ANN F1-score: 0.44295491104422313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split=0.2)  # Increased epochs for more training\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "635494ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2ms/step - accuracy: 0.0144 - loss: -190857625600.0000 - val_accuracy: 0.0137 - val_loss: -2633349726208.0000\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.013424898507266473\n",
      "CNN Precision: 0.00018022789993040557\n",
      "CNN Recall: 0.013424898507266473\n",
      "CNN F1-score: 0.0003556808209387275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
    "precision = precision_score(Y_test, Y_pred_binary, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred_binary, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred_binary, average='weighted')\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2da87f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5ms/step - accuracy: 0.0141 - loss: -3793.4465 - val_accuracy: 0.0137 - val_loss: -15081.2393\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.0136 - loss: -15181.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Accuracy: 0.013424898497760296\n",
      "LSTM Precision: 0.00018022789993040557\n",
      "LSTM Recall: 0.013424898507266473\n",
      "LSTM F1-score: 0.0003556808209387275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy)\n",
    "print(\"LSTM Precision:\", precision)\n",
    "print(\"LSTM Recall:\", recall)\n",
    "print(\"LSTM F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b4042",
   "metadata": {},
   "source": [
    "Unlike previous version, this time we can see that almost all neural networks have severe abnormal `loss` and `val_loss` values. In this research, the normal `val_loss` value is a decimal number between 0 and 1. (Like the first section.)\n",
    "\n",
    "Obviously, these extremely large negative values for `loss` and `val_loss` indicate a severe numerical instability problem. (Bad news) Simultaneously, I observe that by inserting new neural network layers, the classification accuracy can be considerably improved. (Good news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f297aa5",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet6\"><p><b>Section 6</b>: Improvement Works on Previous Results from Classification (A Multi-class Classification Approach for Three Classes (MCATC))</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fd86d",
   "metadata": {},
   "source": [
    "Now I applied several different techniques inside the existing code:\n",
    "1. Dropout Layers: Help prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.\n",
    "2. ReduceLROnPlateau: Reduces learning rate when a metric has stopped improving to help the model converge better.\n",
    "3. Early Stopping: Monitors validation loss and stops training when improvement ceases to prevent overfitting.\n",
    "\n",
    "Simultaneouly, I inserted several layers for my ANN implementation, with an improvement of overall accuracy statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74ebae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7192 - loss: 0.7483 - val_accuracy: 0.7664 - val_loss: 0.6641 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7537 - loss: 0.6867 - val_accuracy: 0.7744 - val_loss: 0.6490 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1ms/step - accuracy: 0.7589 - loss: 0.6774 - val_accuracy: 0.7759 - val_loss: 0.6429 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.6722 - val_accuracy: 0.7777 - val_loss: 0.6400 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7643 - loss: 0.6672 - val_accuracy: 0.7794 - val_loss: 0.6373 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1ms/step - accuracy: 0.7659 - loss: 0.6646 - val_accuracy: 0.7810 - val_loss: 0.6344 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7665 - loss: 0.6634 - val_accuracy: 0.7815 - val_loss: 0.6330 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1ms/step - accuracy: 0.7683 - loss: 0.6603 - val_accuracy: 0.7806 - val_loss: 0.6350 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1ms/step - accuracy: 0.7684 - loss: 0.6601 - val_accuracy: 0.7822 - val_loss: 0.6318 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1ms/step - accuracy: 0.7696 - loss: 0.6584 - val_accuracy: 0.7833 - val_loss: 0.6294 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1ms/step - accuracy: 0.7700 - loss: 0.6574 - val_accuracy: 0.7840 - val_loss: 0.6288 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1ms/step - accuracy: 0.7709 - loss: 0.6565 - val_accuracy: 0.7838 - val_loss: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1ms/step - accuracy: 0.7718 - loss: 0.6543 - val_accuracy: 0.7844 - val_loss: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1ms/step - accuracy: 0.7714 - loss: 0.6556 - val_accuracy: 0.7844 - val_loss: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1ms/step - accuracy: 0.7725 - loss: 0.6539 - val_accuracy: 0.7847 - val_loss: 0.6279 - learning_rate: 0.0010\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 798us/step\n",
      "ANN Accuracy: 0.7825895749668994\n",
      "ANN Precision: 0.8124062099269788\n",
      "ANN Recall: 0.7825895749668994\n",
      "ANN F1-score: 0.7603431000396014\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57538ac2",
   "metadata": {},
   "source": [
    "But there are still some distances between this result and the expected 90% goal. In the next step, I added a few more neural network layers inside my ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3b80b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.7435 - val_accuracy: 0.7731 - val_loss: 0.6507 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7633 - loss: 0.6720 - val_accuracy: 0.7790 - val_loss: 0.6396 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.6609 - val_accuracy: 0.7831 - val_loss: 0.6315 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.6558 - val_accuracy: 0.7845 - val_loss: 0.6277 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.6525 - val_accuracy: 0.7858 - val_loss: 0.6237 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.6495 - val_accuracy: 0.7845 - val_loss: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7761 - loss: 0.6477 - val_accuracy: 0.7868 - val_loss: 0.6238 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.6472 - val_accuracy: 0.7877 - val_loss: 0.6200 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.6459 - val_accuracy: 0.7891 - val_loss: 0.6172 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.6442 - val_accuracy: 0.7894 - val_loss: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.6430 - val_accuracy: 0.7891 - val_loss: 0.6174 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.6427 - val_accuracy: 0.7891 - val_loss: 0.6180 - learning_rate: 0.0010\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 847us/step\n",
      "ANN Accuracy: 0.7879670465536291\n",
      "ANN Precision: 0.820373850677211\n",
      "ANN Recall: 0.7879670465536291\n",
      "ANN F1-score: 0.7661950276679205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9829e38",
   "metadata": {},
   "source": [
    "Seems like adding layers may not improved ANN accuracy obviously. Then I tried to adjust the numbers of neurons and the dropout rate, in order to find the optimal accuracy. There are five values in the `Dropout()` function: 0.1, 0.3, 0.5, 0.7, and 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601e6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: 0.7046 - val_accuracy: 0.7831 - val_loss: 0.6283 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.6427 - val_accuracy: 0.7890 - val_loss: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.6284 - val_accuracy: 0.7947 - val_loss: 0.6022 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.6205 - val_accuracy: 0.7957 - val_loss: 0.5991 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2ms/step - accuracy: 0.7883 - loss: 0.6165 - val_accuracy: 0.7986 - val_loss: 0.5925 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.6141 - val_accuracy: 0.7996 - val_loss: 0.5907 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.6110 - val_accuracy: 0.7996 - val_loss: 0.5910 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2ms/step - accuracy: 0.7921 - loss: 0.6097 - val_accuracy: 0.8002 - val_loss: 0.5908 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.6074 - val_accuracy: 0.8022 - val_loss: 0.5866 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.6069 - val_accuracy: 0.8027 - val_loss: 0.5851 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.6051 - val_accuracy: 0.8016 - val_loss: 0.5864 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.6043 - val_accuracy: 0.8025 - val_loss: 0.5843 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.6039 - val_accuracy: 0.8021 - val_loss: 0.5854 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.6017 - val_accuracy: 0.8033 - val_loss: 0.5840 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.6012 - val_accuracy: 0.8022 - val_loss: 0.5845 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.6016 - val_accuracy: 0.8033 - val_loss: 0.5832 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.6000 - val_accuracy: 0.8045 - val_loss: 0.5813 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.5991 - val_accuracy: 0.8043 - val_loss: 0.5816 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.5994 - val_accuracy: 0.8036 - val_loss: 0.5822 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.5976 - val_accuracy: 0.8044 - val_loss: 0.5807 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5998 - val_accuracy: 0.8058 - val_loss: 0.5791 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5978 - val_accuracy: 0.8049 - val_loss: 0.5810 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5980 - val_accuracy: 0.8051 - val_loss: 0.5785 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.5966 - val_accuracy: 0.8043 - val_loss: 0.5819 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.5955 - val_accuracy: 0.8051 - val_loss: 0.5800 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.5956 - val_accuracy: 0.8050 - val_loss: 0.5800 - learning_rate: 0.0010\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 862us/step\n",
      "ANN Accuracy: 0.8041401523095271\n",
      "ANN Precision: 0.8363437736417787\n",
      "ANN Recall: 0.8041401523095271\n",
      "ANN F1-score: 0.7853252608801907\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9ed98",
   "metadata": {},
   "source": [
    "From training we can see that although the overall accuracy is high, most of these training steps take longer time and much more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db2e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
