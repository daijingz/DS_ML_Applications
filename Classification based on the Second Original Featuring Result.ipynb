{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d61824",
   "metadata": {},
   "source": [
    "# Classification based on the Second Original Featuring Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e6806",
   "metadata": {},
   "source": [
    "<p><b>Author</b>: Jingze Dai</p>\n",
    "<p><b>McMaster University</b>, Honors Computer Science (Coop) student</p>\n",
    "<p><b>Personal Email Address</b>: <a>david1147062956@gmail.com</a>, or <a>dai.jingze@icloud.com</a></p>\n",
    "<a href=\"https://github.com/daijingz\">Github Homepage</a>\n",
    "<a href=\"https://www.linkedin.com/in/jingze-dai/\">Linkedin Webpage</a>\n",
    "<a href=\"https://leetcode.com/david1147062956/\">Leetcode Webpage</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dfb4a",
   "metadata": {},
   "source": [
    "<i>The original research's second featuring method selected distinct features from the Recursive Feature Elimination (RFE) implementation. This notebook includes misbehavior classification by using these distinct features.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd76c2",
   "metadata": {},
   "source": [
    "<i>Your Feedback is important for Jingze's further development. If you want to give feedback and suggestions, or you want to participate in working and learning together, please email Jingze at dai.jingze@icloud.com. If you want Jingze to provide contributions to your research or opensource project or you want Jingze to help you with any programming issues, please email Jingze at david1147062956@gmail.com. Thank you for your help.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50da20",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Section 1: Selected Features](#bullet1)\n",
    "* [Section 2: Extract and Load Datasets](#bullet2)\n",
    "* [Section 3: Classification (Binary Classification Approach (BCA))](#bullet3)\n",
    "* [Section 4: Classification (A Multi-class Classification Approach for Three Classes (MCATC))](#bullet4)\n",
    "* [Section 5: Classification (A Classic Learning Approach for Multi-class classification (C-LAMC))](#bullet5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a8975",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet1\"><p><b>Section 1</b>: Selected Features</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24749304",
   "metadata": {},
   "source": [
    "There are 12 features selected: `posx`, `posy`, `posx_n`,\n",
    "`posy_n`, `spdx`, `spdy`, `spdx_n`, `aclx_n`, `hedx`, `hedy`, `hedx_n`, `hedy_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c92927",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet2\"><p><b>Section 2</b>: Extract and Load Datasets</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770e691",
   "metadata": {},
   "source": [
    "Then the next step is to install all necessary packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee57dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\david\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c409ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c656e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d367998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30596c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\david\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from scipy) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9ae7c",
   "metadata": {},
   "source": [
    "<p>There are two methods to download the package, choose one of them to download the dataset: </p>\n",
    "<p><b>Method 1</b>: Using gdown commands (Sometimes with errors)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83f225",
   "metadata": {},
   "source": [
    "<p>Here we download the CSV VANETs dataset file from remote google drive, and savce it in your local computer's download folder. </p>\n",
    "The <b>correct</b> dataset name is \"mixalldata_clean.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ea46db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9\n",
      "From (redirected): https://drive.google.com/uc?id=1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9&confirm=t&uuid=91a42141-951e-4ad4-b50c-54c20847c43e\n",
      "To: C:\\Users\\david\\Downloads\\mixalldata_clean.csv\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.21G/1.21G [00:23<00:00, 51.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mixalldata_clean.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "file_id = '1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9'\n",
    "file_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "output_file = 'mixalldata_clean.csv'\n",
    "gdown.download(file_url, output_file, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6494357",
   "metadata": {},
   "source": [
    "<p><b>Method 2</b>: Direct downloading from sources</p>\n",
    "At first, go to the webpage <a href=\"https://data.mendeley.com/datasets/k62n4z9gdz/1\">Dataset for Misbehaviors in VANETs</a>.\n",
    "Then click the button \"Download All 314 MB\". Then de-compress this compressed folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d67c6",
   "metadata": {},
   "source": [
    "<b>Expected Outcome</b>\n",
    "<p>After downloading the dataset, to have a good double check, the program below prints out the first 5 records inside.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c851ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type      sendTime  sender  senderPseudo  messageID  class        posx  \\\n",
      "0     4  72002.302942  130137     101301377  422013806      0  266.982401   \n",
      "1     4  72003.302942  130137     101301377  422023410      0  266.827208   \n",
      "2     4  72004.302942  130137     101301377  422032081      0  266.420297   \n",
      "3     4  72005.302942  130137     101301377  422040712      0  268.912026   \n",
      "4     4  72006.302942  130137     101301377  422052949      0  268.242276   \n",
      "\n",
      "        posy  posz    posx_n  ...  aclz    aclx_n    acly_n  aclz_n      hedx  \\\n",
      "0  32.336955   0.0  3.480882  ...   0.0  0.000862  0.000862     0.0 -0.102790   \n",
      "1  34.624145   0.0  3.546261  ...   0.0  0.000107  0.001040     0.0 -0.099856   \n",
      "2  38.836461   0.0  3.544045  ...   0.0  0.000172  0.001661     0.0 -0.099856   \n",
      "3  45.414229   0.0  3.340080  ...   0.0  0.000171  0.001654     0.0 -0.100172   \n",
      "4  53.729986   0.0  3.328872  ...   0.0  0.000193  0.001852     0.0 -0.097105   \n",
      "\n",
      "       hedy  hedz     hedx_n     hedy_n  hedz_n  \n",
      "0  0.994703   0.0  20.038218  17.541001     0.0  \n",
      "1  0.995002   0.0  20.441139  14.467283     0.0  \n",
      "2  0.995002   0.0  20.850473  11.941528     0.0  \n",
      "3  0.994970   0.0  21.323229   9.633965     0.0  \n",
      "4  0.995274   0.0  21.788034   7.824555     0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "# Load the dataset\n",
    "output_file = 'mixalldata_clean.csv'\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1ae6c",
   "metadata": {},
   "source": [
    "<b>Important: before completing later sections, please run all of this section programs in order to prevent possible errors.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a2520",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet3\"><p><b>Section 3</b>: Classification (Binary Classification Approach (BCA))</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9bb02",
   "metadata": {},
   "source": [
    "<p>At first we need to divide dataset into training data and testing data. This is completed on each algorithm's implementation. </p>\n",
    "<p>80% data is training data, while 20% remaining is testing data. (This is normal setting). However, in order to improve accuracy, some models' training-testing data ratio s are customized.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c552ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7163430689148963\n",
      "Logistic Regression Precision: 0.8915322944782814\n",
      "Logistic Regression Recall: 0.34267433384627843\n",
      "Logistic Regression F1-score: 0.4950633517946889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Logistic Regression Precision:\", precision)\n",
    "print(\"Logistic Regression Recall:\", recall)\n",
    "print(\"Logistic Regression F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aafeec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "KNN Accuracy when n_neighbors = 1 : 0.8439609867253451\n",
      "KNN Precision: 0.7930297466030114\n",
      "KNN Recall: 0.8328300300439282\n",
      "KNN F1-score: 0.8124427422040043\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 2 : 0.8684976571376701\n",
      "KNN Precision: 0.9037141461886465\n",
      "KNN Recall: 0.756543906944814\n",
      "KNN F1-score: 0.8236062214888663\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 3 : 0.8565063337099859\n",
      "KNN Precision: 0.8381049981440537\n",
      "KNN Recall: 0.8011431348274306\n",
      "KNN F1-score: 0.8192073573517319\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 4 : 0.8629229907255831\n",
      "KNN Precision: 0.8989349343395384\n",
      "KNN Recall: 0.7460805979474482\n",
      "KNN F1-score: 0.8154061772237268\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 5 : 0.8516015036887953\n",
      "KNN Precision: 0.8545473359259802\n",
      "KNN Recall: 0.7644116365263203\n",
      "KNN F1-score: 0.8069703292788436\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 6 : 0.8509958338680548\n",
      "KNN Precision: 0.8996877116228764\n",
      "KNN Recall: 0.7122185069054754\n",
      "KNN F1-score: 0.7950515126596721\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 7 : 0.8443146853803513\n",
      "KNN Precision: 0.8663451222755073\n",
      "KNN Recall: 0.7287754495983215\n",
      "KNN F1-score: 0.7916280024549591\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 8 : 0.8496045148224777\n",
      "KNN Precision: 0.9141499761443117\n",
      "KNN Recall: 0.6946125336017618\n",
      "KNN F1-score: 0.7894018255333604\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 9 : 0.8452756188943944\n",
      "KNN Precision: 0.8883944567648967\n",
      "KNN Recall: 0.707605857601808\n",
      "KNN F1-score: 0.7877606486778916\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 10 : 0.8476623022965372\n",
      "KNN Precision: 0.9220169381107491\n",
      "KNN Recall: 0.6823018508448168\n",
      "KNN F1-score: 0.7842504466244941\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neighbor_amount = 1\n",
    "\n",
    "print(\"*********\")\n",
    "while n_neighbor_amount < 11:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor_amount)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"KNN Accuracy when n_neighbors =\", n_neighbor_amount, \":\", accuracy)\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "    print(\"KNN Precision:\", precision)\n",
    "    print(\"KNN Recall:\", recall)\n",
    "    print(\"KNN F1-score:\", f1)\n",
    "    print(\"*********\")\n",
    "    n_neighbor_amount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5687e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8981707832390659\n",
      "Random Forest Precision: 0.903764437828983\n",
      "Random Forest Recall: 0.8383297272906085\n",
      "Random Forest F1-score: 0.8698181876386801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "print(\"Random Forest Precision:\", precision)\n",
    "print(\"Random Forest Recall:\", recall)\n",
    "print(\"Random Forest F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d11e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8627805722406027\n",
      "Decision Tree Precision: 0.819138748877226\n",
      "Decision Tree Recall: 0.8499869051470474\n",
      "Decision Tree F1-score: 0.8342777649669416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "print(\"Decision Tree Precision:\", precision)\n",
    "print(\"Decision Tree Recall:\", recall)\n",
    "print(\"Decision Tree F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27ae9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6771456929636881\n",
      "Naive Bayes Precision: 0.7058645996287782\n",
      "Naive Bayes Recall: 0.34941796043375956\n",
      "Naive Bayes F1-score: 0.46744213934524526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.31, random_state=42)\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "print(\"Naive Bayes Precision:\", precision)\n",
    "print(\"Naive Bayes Recall:\", recall)\n",
    "print(\"Naive Bayes F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "472f98c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.8146306040108802\n",
      "MLP Precision: 0.98294437548434\n",
      "MLP Recall: 0.5527851377045513\n",
      "MLP F1-score: 0.707620759113709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42,\n",
    "                    max_iter=100, tol=0.001)\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"MLP Accuracy:\", accuracy)\n",
    "print(\"MLP Precision:\", precision)\n",
    "print(\"MLP Recall:\", recall)\n",
    "print(\"MLP F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "747856ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 0.6609 - val_accuracy: 0.7556 - val_loss: 0.5082\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - accuracy: 0.7552 - loss: 0.5082\n",
      "ANN Accuracy: 0.7555269598960876\n",
      "ANN Precision: 0.9728088362108508\n",
      "ANN Recall: 0.4089753824912163\n",
      "ANN F1-score: 0.5758567227723579\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "610ba1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5481 - val_accuracy: 0.7939 - val_loss: 0.4566\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step\n",
      "CNN Accuracy: 0.7931457582767051\n",
      "CNN Precision: 0.9625828802666725\n",
      "CNN Recall: 0.510075707613571\n",
      "CNN F1-score: 0.6668078369684686\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
    "precision = precision_score(Y_test, Y_pred_binary)\n",
    "recall = recall_score(Y_test, Y_pred_binary)\n",
    "f1 = f1_score(Y_test, Y_pred_binary)\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5906c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.5018 - val_accuracy: 0.7913 - val_loss: 0.4606\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.4617\n",
      "LSTM Accuracy: 0.790992259979248\n",
      "LSTM Precision: 0.9751573919418349\n",
      "LSTM Recall: 0.49761846910951957\n",
      "LSTM F1-score: 0.6589683350357507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy)\n",
    "print(\"LSTM Precision:\", precision)\n",
    "print(\"LSTM Recall:\", recall)\n",
    "print(\"LSTM F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dc253",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet4\"><p><b>Section 4</b>: Classification (A Multi-class Classification Approach for Three Classes (MCATC))</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619515a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6687314738591653\n",
      "Logistic Regression Precision: 0.6374461945250697\n",
      "Logistic Regression Recall: 0.6687314738591653\n",
      "Logistic Regression F1-score: 0.5787906916350495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Logistic Regression Precision:\", precision)\n",
    "print(\"Logistic Regression Recall:\", recall)\n",
    "print(\"Logistic Regression F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df531755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "KNN Accuracy when n_neighbors = 1 : 0.8027159674597237\n",
      "KNN Precision: 0.8066590359961757\n",
      "KNN Recall: 0.8027159674597237\n",
      "KNN F1-score: 0.804227308527448\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 2 : 0.8293560493425274\n",
      "KNN Precision: 0.8267237731004661\n",
      "KNN Recall: 0.8293560493425274\n",
      "KNN F1-score: 0.8231326044770159\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 3 : 0.824667194606252\n",
      "KNN Precision: 0.822739680871316\n",
      "KNN Recall: 0.824667194606252\n",
      "KNN F1-score: 0.8223984559151134\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 4 : 0.8278332670800455\n",
      "KNN Precision: 0.8242200153592177\n",
      "KNN Recall: 0.8278332670800455\n",
      "KNN F1-score: 0.8218003239306294\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 5 : 0.8204494163972192\n",
      "KNN Precision: 0.8173448159450895\n",
      "KNN Recall: 0.8204494163972192\n",
      "KNN F1-score: 0.8158442803840729\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 6 : 0.817145620553335\n",
      "KNN Precision: 0.8142309332525839\n",
      "KNN Recall: 0.817145620553335\n",
      "KNN F1-score: 0.8089476523027588\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 7 : 0.8119590836387767\n",
      "KNN Precision: 0.8088651237374546\n",
      "KNN Recall: 0.8119590836387767\n",
      "KNN F1-score: 0.804845653561703\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 8 : 0.8162081626137392\n",
      "KNN Precision: 0.8150302463796603\n",
      "KNN Recall: 0.8162081626137392\n",
      "KNN F1-score: 0.8063203926445421\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 9 : 0.8137729630244052\n",
      "KNN Precision: 0.8122217406761312\n",
      "KNN Recall: 0.8137729630244052\n",
      "KNN F1-score: 0.804486160644076\n",
      "*********\n",
      "KNN Accuracy when n_neighbors = 10 : 0.814222129015497\n",
      "KNN Precision: 0.8142885276853077\n",
      "KNN Recall: 0.814222129015497\n",
      "KNN F1-score: 0.8031408706126074\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neighbor_amount = 1\n",
    "\n",
    "print(\"*********\")\n",
    "while n_neighbor_amount < 11:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor_amount)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"KNN Accuracy when n_neighbors =\", n_neighbor_amount, \":\", accuracy)\n",
    "    precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "    recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "    f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "    print(\"KNN Precision:\", precision)\n",
    "    print(\"KNN Recall:\", recall)\n",
    "    print(\"KNN F1-score:\", f1)\n",
    "    print(\"*********\")\n",
    "    n_neighbor_amount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031651a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8770443312747863\n",
      "Random Forest Precision: 0.8756821197468284\n",
      "Random Forest Recall: 0.8770443312747863\n",
      "Random Forest F1-score: 0.875217927070579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "print(\"Random Forest Precision:\", precision)\n",
    "print(\"Random Forest Recall:\", recall)\n",
    "print(\"Random Forest F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c525038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8322498051527321\n",
      "Decision Tree Precision: 0.8343664982332558\n",
      "Decision Tree Recall: 0.8322498051527321\n",
      "Decision Tree F1-score: 0.8331118608663234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "print(\"Decision Tree Precision:\", precision)\n",
    "print(\"Decision Tree Recall:\", recall)\n",
    "print(\"Decision Tree F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4181f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6558418184492975\n",
      "Naive Bayes Precision: 0.6164199640285972\n",
      "Naive Bayes Recall: 0.6558418184492975\n",
      "Naive Bayes F1-score: 0.5848392450226766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "print(\"Naive Bayes Precision:\", precision)\n",
    "print(\"Naive Bayes Recall:\", recall)\n",
    "print(\"Naive Bayes F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c1d8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.7682882550136002\n",
      "MLP Precision: 0.7805252032273552\n",
      "MLP Recall: 0.7682882550136002\n",
      "MLP F1-score: 0.7425781760165167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42,\n",
    "                    max_iter=100, tol=0.001)\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"MLP Accuracy:\", accuracy)\n",
    "print(\"MLP Precision:\", precision)\n",
    "print(\"MLP Recall:\", recall)\n",
    "print(\"MLP F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26e77bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.7609 - val_accuracy: 0.7539 - val_loss: 0.6875 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.7030 - val_accuracy: 0.7658 - val_loss: 0.6652 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.6891 - val_accuracy: 0.7674 - val_loss: 0.6584 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.6835 - val_accuracy: 0.7737 - val_loss: 0.6515 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.6767 - val_accuracy: 0.7755 - val_loss: 0.6431 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6727 - val_accuracy: 0.7763 - val_loss: 0.6392 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.6695 - val_accuracy: 0.7789 - val_loss: 0.6363 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.6650 - val_accuracy: 0.7790 - val_loss: 0.6341 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.6641 - val_accuracy: 0.7820 - val_loss: 0.6303 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.6619 - val_accuracy: 0.7812 - val_loss: 0.6325 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2ms/step - accuracy: 0.7682 - loss: 0.6609 - val_accuracy: 0.7833 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.6589 - val_accuracy: 0.7840 - val_loss: 0.6296 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1ms/step - accuracy: 0.7700 - loss: 0.6576 - val_accuracy: 0.7819 - val_loss: 0.6302 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1ms/step - accuracy: 0.7706 - loss: 0.6576 - val_accuracy: 0.7832 - val_loss: 0.6278 - learning_rate: 0.0010\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 859us/step\n",
      "ANN Accuracy: 0.7821623195119585\n",
      "ANN Precision: 0.8138739003169817\n",
      "ANN Recall: 0.7821623195119585\n",
      "ANN F1-score: 0.7577483882683488\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ee522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in target: [0 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.7208 - val_accuracy: 0.7632 - val_loss: 0.6572 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.6505 - val_accuracy: 0.7755 - val_loss: 0.6343 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.6334 - val_accuracy: 0.7814 - val_loss: 0.6236 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.6240 - val_accuracy: 0.7843 - val_loss: 0.6155 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.6162 - val_accuracy: 0.7855 - val_loss: 0.6124 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.6118 - val_accuracy: 0.7876 - val_loss: 0.6088 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2132s\u001b[0m 33ms/step - accuracy: 0.7870 - loss: 0.6080 - val_accuracy: 0.7879 - val_loss: 0.6087 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.6050 - val_accuracy: 0.7871 - val_loss: 0.6094 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.6039 - val_accuracy: 0.7886 - val_loss: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.5999 - val_accuracy: 0.7907 - val_loss: 0.6021 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5ms/step - accuracy: 0.7913 - loss: 0.5978 - val_accuracy: 0.7909 - val_loss: 0.6011 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.5958 - val_accuracy: 0.7922 - val_loss: 0.5965 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5952 - val_accuracy: 0.7917 - val_loss: 0.6002 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.5936 - val_accuracy: 0.7930 - val_loss: 0.5966 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.5926 - val_accuracy: 0.7924 - val_loss: 0.5959 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.5904 - val_accuracy: 0.7947 - val_loss: 0.5927 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5891 - val_accuracy: 0.7955 - val_loss: 0.5903 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.5878 - val_accuracy: 0.7940 - val_loss: 0.5932 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.5876 - val_accuracy: 0.7952 - val_loss: 0.5893 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5871 - val_accuracy: 0.7943 - val_loss: 0.5945 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.5861 - val_accuracy: 0.7962 - val_loss: 0.5878 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5856 - val_accuracy: 0.7959 - val_loss: 0.5887 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.5849 - val_accuracy: 0.7939 - val_loss: 0.5907 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.5846 - val_accuracy: 0.7945 - val_loss: 0.5915 - learning_rate: 0.0010\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step\n",
      "CNN Accuracy: 0.7954463645725411\n",
      "CNN Precision: 0.8183120291541826\n",
      "CNN Recall: 0.7954463645725411\n",
      "CNN F1-score: 0.7756720393402297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Ensure 'class' column exists in df\n",
    "df['class'] = df['class'].apply(characterize_class).astype(int)\n",
    "\n",
    "# Check the unique classes in the target\n",
    "unique_classes = df['class'].unique()\n",
    "print(f\"Unique classes in target: {unique_classes}\")\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'aclx_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = to_categorical(df['class'].values, num_classes=3)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the input data to fit the Conv1D layer\n",
    "sequence_length = X_train.shape[1]\n",
    "X_train = X_train.reshape((X_train.shape[0], sequence_length, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], sequence_length, 1))\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=2, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(Y_test_classes, Y_pred)\n",
    "precision = precision_score(Y_test_classes, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test_classes, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test_classes, Y_pred, average='weighted')\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c87af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
