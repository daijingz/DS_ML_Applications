{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adbcd2e",
   "metadata": {},
   "source": [
    "# Classification based on the First Original Featuring Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfbcae",
   "metadata": {},
   "source": [
    "<p><b>Author</b>: Jingze Dai</p>\n",
    "<p><b>McMaster University</b>, Honors Computer Science (Coop) student</p>\n",
    "<p><b>Personal Email Address</b>: <a>david1147062956@gmail.com</a>, or <a>dai.jingze@icloud.com</a></p>\n",
    "<a href=\"https://github.com/daijingz\">Github Homepage</a>\n",
    "<a href=\"https://www.linkedin.com/in/jingze-dai/\">Linkedin Webpage</a>\n",
    "<a href=\"https://leetcode.com/david1147062956/\">Leetcode Webpage</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2369d",
   "metadata": {},
   "source": [
    "<i>The original research's first featuring method selected distinct features from the Recursive Feature Elimination (RFE) implementation. This notebook includes misbehavior classification by using these distinct features.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68954d23",
   "metadata": {},
   "source": [
    "<i>Your Feedback is important for Jingze's further development. If you want to give feedback and suggestions, or you want to participate in working and learning together, please email Jingze at dai.jingze@icloud.com. If you want Jingze to provide contributions to your research or opensource project or you want Jingze to help you with any programming issues, please email Jingze at david1147062956@gmail.com. Thank you for your help.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9efb006",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Section 1: Selected Features](#bullet1)\n",
    "* [Section 2: Extract and Load Datasets](#bullet2)\n",
    "* [Section 3: Classification (Binary Classification Approach (BCA))](#bullet3)\n",
    "* [Section 4: Classification (A Multi-class Classification Approach for Three Classes (MCATC))](#bullet4)\n",
    "* [Section 5: Classification (A Classic Learning Approach for Multi-class classification (C-LAMC))](#bullet5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85ad58",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet1\"><p><b>Section 1</b>: Selected Features</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9fd96",
   "metadata": {},
   "source": [
    "There are 24 features selected: `posx`, `posy`, `posz', 'posx_n`, `posy_n`, `posz_n`, `spdx`, `spdy`, `spdz`, `spdx_n`, `spdy_n`, `spdz_n`, `aclx`, `acly`, `aclz`, `aclx_n`, `acly_n`, `aclz_n`,\n",
    "`hedx`, `hedy`, `hedz`, `hedx_n`, `hedy_n`, `hedz_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad1e14",
   "metadata": {},
   "source": [
    "In the later algorithm implementations, because there are some features with constant values, all of them are deleted from classification features. There are 8 deleted features: `posz`, `posz_n`, `spdz`, `spdz_n`,`aclz`, `aclz_n`, `hedz`, and `hedz_n`.\n",
    "\n",
    "16 features Remaining: `posx`, `posy`, `posx_n`, `posy_n`, `spdx`, `spdy`, `spdx_n`, `spdy_n`, `aclx`, `acly`, `aclx_n`, `acly_n`, `hedx`, `hedy`, `hedx_n`, `hedy_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b896d6a",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet2\"><p><b>Section 2</b>: Extract and Load Datasets</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcb44a",
   "metadata": {},
   "source": [
    "Then the next step is to install all necessary packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc9d4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\david\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\david\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc47bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658fcd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: optree in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: namex in c:\\users\\david\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\david\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270ca61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e1b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\david\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\david\\anaconda3\\lib\\site-packages (from scipy) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317a2d6",
   "metadata": {},
   "source": [
    "<p>There are two methods to download the package, choose one of them to download the dataset: </p>\n",
    "<p><b>Method 1</b>: Using gdown commands (Sometimes with errors)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac7fa6",
   "metadata": {},
   "source": [
    "<p>Here we download the CSV VANETs dataset file from remote google drive, and savce it in your local computer's download folder. </p>\n",
    "The <b>correct</b> dataset name is \"mixalldata_clean.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40052d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9\n",
      "From (redirected): https://drive.google.com/uc?id=1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9&confirm=t&uuid=8c8a8d7a-20cf-4464-9d5f-8fced0a9ad6e\n",
      "To: C:\\Users\\david\\Downloads\\mixalldata_clean.csv\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.21G/1.21G [00:25<00:00, 47.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mixalldata_clean.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "file_id = '1mbQUfSEe2EU2sh40Q1Q0KiZD-k7vRuU9'\n",
    "file_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "output_file = 'mixalldata_clean.csv'\n",
    "gdown.download(file_url, output_file, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2d40f",
   "metadata": {},
   "source": [
    "<p><b>Method 2</b>: Direct downloading from sources</p>\n",
    "At first, go to the webpage <a href=\"https://data.mendeley.com/datasets/k62n4z9gdz/1\">Dataset for Misbehaviors in VANETs</a>.\n",
    "Then click the button \"Download All 314 MB\". Then de-compress this compressed folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af857c7",
   "metadata": {},
   "source": [
    "<b>Expected Outcome</b>\n",
    "<p>After downloading the dataset, to have a good double check, the program below prints out the first 5 records inside.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54fa1d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type      sendTime  sender  senderPseudo  messageID  class        posx  \\\n",
      "0     4  72002.302942  130137     101301377  422013806      0  266.982401   \n",
      "1     4  72003.302942  130137     101301377  422023410      0  266.827208   \n",
      "2     4  72004.302942  130137     101301377  422032081      0  266.420297   \n",
      "3     4  72005.302942  130137     101301377  422040712      0  268.912026   \n",
      "4     4  72006.302942  130137     101301377  422052949      0  268.242276   \n",
      "\n",
      "        posy  posz    posx_n  ...  aclz    aclx_n    acly_n  aclz_n      hedx  \\\n",
      "0  32.336955   0.0  3.480882  ...   0.0  0.000862  0.000862     0.0 -0.102790   \n",
      "1  34.624145   0.0  3.546261  ...   0.0  0.000107  0.001040     0.0 -0.099856   \n",
      "2  38.836461   0.0  3.544045  ...   0.0  0.000172  0.001661     0.0 -0.099856   \n",
      "3  45.414229   0.0  3.340080  ...   0.0  0.000171  0.001654     0.0 -0.100172   \n",
      "4  53.729986   0.0  3.328872  ...   0.0  0.000193  0.001852     0.0 -0.097105   \n",
      "\n",
      "       hedy  hedz     hedx_n     hedy_n  hedz_n  \n",
      "0  0.994703   0.0  20.038218  17.541001     0.0  \n",
      "1  0.995002   0.0  20.441139  14.467283     0.0  \n",
      "2  0.995002   0.0  20.850473  11.941528     0.0  \n",
      "3  0.994970   0.0  21.323229   9.633965     0.0  \n",
      "4  0.995274   0.0  21.788034   7.824555     0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "# Load the dataset\n",
    "output_file = 'mixalldata_clean.csv'\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2ad2c",
   "metadata": {},
   "source": [
    "<b>Important: before completing later sections, please run all of this section programs in order to prevent possible errors.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d2713",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet3\"><p><b>Section 3</b>: Classification (Binary Classification Approach (BCA))</p></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d75a7",
   "metadata": {},
   "source": [
    "<p>At first we need to divide dataset into training data and testing data. This is completed on each algorithm's implementation. </p>\n",
    "<p>80% data is training data, while 20% remaining is testing data. (This is normal setting). However, in order to improve accuracy, some models' training-testing data ratio s are customized.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96dc7930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7163900200637909\n",
      "Logistic Regression Precision: 0.8919502374664886\n",
      "Logistic Regression Recall: 0.3426010559727252\n",
      "Logistic Regression F1-score: 0.49505127061970583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Logistic Regression Precision:\", precision)\n",
    "print(\"Logistic Regression Recall:\", recall)\n",
    "print(\"Logistic Regression F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73735ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 10}\n",
      "KNN Accuracy: 0.688936118266814\n",
      "KNN Precision: 0.7978994615770771\n",
      "KNN Recall: 0.3126304056894484\n",
      "KNN F1-score: 0.4492407448459321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df.drop(columns=['class'])  # Assuming 'class' is the target variable\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "# Reduce dimensionality using PCA\n",
    "pca = PCA(n_components=10)  # Adjust the number of components as needed\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter grid for KNN\n",
    "param_grid = {'n_neighbors': range(1, 11)}\n",
    "\n",
    "# Grid search for parameter optimization\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best estimator\n",
    "knn = grid_search.best_estimator_\n",
    "\n",
    "# Fitting the model and making predictions\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"KNN Accuracy:\", accuracy)\n",
    "print(\"KNN Precision:\", precision)\n",
    "print(\"KNN Recall:\", recall)\n",
    "print(\"KNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f2cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8951111333694336\n",
      "Random Forest Precision: 0.9040428026848345\n",
      "Random Forest Recall: 0.8295749497660894\n",
      "Random Forest F1-score: 0.8652094864203886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "print(\"Random Forest Precision:\", precision)\n",
    "print(\"Random Forest Recall:\", recall)\n",
    "print(\"Random Forest F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "574ba784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8611779730249999\n",
      "Decision Tree Precision: 0.8166601213719925\n",
      "Decision Tree Recall: 0.848962425474881\n",
      "Decision Tree F1-score: 0.8324980455398653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "print(\"Decision Tree Precision:\", precision)\n",
    "print(\"Decision Tree Recall:\", recall)\n",
    "print(\"Decision Tree F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48eca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6783654132559767\n",
      "Naive Bayes Precision: 0.7058788536755848\n",
      "Naive Bayes Recall: 0.3545573386785523\n",
      "Naive Bayes F1-score: 0.4720218521268696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.31, random_state=42)\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "print(\"Naive Bayes Precision:\", precision)\n",
    "print(\"Naive Bayes Recall:\", recall)\n",
    "print(\"Naive Bayes F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4e7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.8179109242803171\n",
      "MLP Precision: 0.9652447320283563\n",
      "MLP Recall: 0.5718682386698909\n",
      "MLP F1-score: 0.7182202158370953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42,\n",
    "                    max_iter=100, tol=0.001)\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"MLP Accuracy:\", accuracy)\n",
    "print(\"MLP Precision:\", precision)\n",
    "print(\"MLP Recall:\", recall)\n",
    "print(\"MLP F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71270c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1ms/step - accuracy: 0.6723 - loss: 0.7533 - val_accuracy: 0.7651 - val_loss: 0.4963\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 735us/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 770us/step - accuracy: 0.7642 - loss: 0.4966\n",
      "ANN Accuracy: 0.7647606730461121\n",
      "ANN Precision: 0.97890629119865\n",
      "ANN Recall: 0.42955489476911685\n",
      "ANN F1-score: 0.5970970206264323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features]\n",
    "Y = (df['class'] != 0).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"ANN Accuracy:\", accuracy)\n",
    "print(\"ANN Precision:\", precision)\n",
    "print(\"ANN Recall:\", recall)\n",
    "print(\"ANN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c865478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5662 - val_accuracy: 0.7926 - val_loss: 0.4585\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step\n",
      "CNN Accuracy: 0.7912442367464732\n",
      "CNN Precision: 0.9566889146836912\n",
      "CNN Recall: 0.5085870097613842\n",
      "CNN F1-score: 0.664120042203124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
    "precision = precision_score(Y_test, Y_pred_binary)\n",
    "recall = recall_score(Y_test, Y_pred_binary)\n",
    "f1 = f1_score(Y_test, Y_pred_binary)\n",
    "\n",
    "print(\"CNN Accuracy:\", accuracy)\n",
    "print(\"CNN Precision:\", precision)\n",
    "print(\"CNN Recall:\", recall)\n",
    "print(\"CNN F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8979bf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63897/63897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 7ms/step - accuracy: 0.7586 - loss: 0.5052 - val_accuracy: 0.7879 - val_loss: 0.4656\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step\n",
      "\u001b[1m19968/19968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.4673\n",
      "LSTM Accuracy: 0.7871015667915344\n",
      "LSTM Precision: 0.9860939114522121\n",
      "LSTM Recall: 0.48215298105959803\n",
      "LSTM F1-score: 0.6476405588681727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = (df['class'] != 0).astype(int).values\n",
    "\n",
    "sequence_length = len(features)\n",
    "X = X.reshape(-1, sequence_length, 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy)\n",
    "print(\"LSTM Precision:\", precision)\n",
    "print(\"LSTM Recall:\", recall)\n",
    "print(\"LSTM F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc86f09",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"bullet4\"><p><b>Section 4</b>: Classification (A Multi-class Classification Approach for Three Classes (MCATC))</p></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0751ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6741527665181967\n",
      "Logistic Regression Precision: 0.714590780416076\n",
      "Logistic Regression Recall: 0.6741527665181967\n",
      "Logistic Regression F1-score: 0.5894611284036861\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def characterize_class(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value >= 1 and value <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "features = ['posx', 'posy', 'posx_n', 'posy_n', 'spdx', 'spdy', 'spdx_n', 'spdy_n', 'aclx', 'acly', \n",
    "            'aclx_n', 'acly_n', 'hedx', 'hedy', 'hedx_n', 'hedy_n']\n",
    "X = df[features].values\n",
    "Y = df['class'].apply(characterize_class).astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Logistic Regression Precision:\", precision)\n",
    "print(\"Logistic Regression Recall:\", recall)\n",
    "print(\"Logistic Regression F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb68f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
